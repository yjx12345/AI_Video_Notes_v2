import os
import asyncio
import subprocess
import httpx
import logging
from functools import partial
from sqlmodel import Session
from app.core.config import settings
from app.database import engine as db_engine
from app.models import SystemConfig
# [P2 é‡æ„] å¼•å…¥ tenacity é‡è¯•æ¨¡å—
from tenacity import retry, stop_after_attempt, wait_exponential, before_sleep_log

# é…ç½®æ—¥å¿—
logger = logging.getLogger("uvicorn.error")


def get_current_api_key(key_name: str, default_value: str) -> str:
    """è¾…åŠ©å‡½æ•°ï¼šè·å–å½“å‰ç”Ÿæ•ˆçš„ API Key (æ•°æ®åº“ä¼˜å…ˆ > é…ç½®æ–‡ä»¶)"""
    try:
        with Session(db_engine) as session:
            conf = session.get(SystemConfig, key_name)
            if conf and conf.value:
                return conf.value
    except Exception as e:
        logger.error(f"è¯»å–æ•°æ®åº“é…ç½®å¤±è´¥: {e}ï¼Œå›é€€åˆ°é»˜è®¤é…ç½®")
    return default_value


class MediaEngine:
    """åª’ä½“å¤„ç†å¼•æ“ (FFmpeg)"""

    @staticmethod
    async def extract_audio(video_path: str, output_dir: str) -> str:
        filename = os.path.basename(video_path)
        audio_filename = f"optimized_{os.path.splitext(filename)[0]}.wav"
        audio_path = os.path.join(output_dir, audio_filename)

        ffmpeg_exe = settings.FFMPEG_PATH

        logger.info(f"ğŸ¬ FFmpeg å¼€å§‹æå–: {video_path} -> {audio_path}")

        command = [
            ffmpeg_exe, "-y", "-i", video_path,
            "-vn", "-ac", "1", "-ar", "16000", "-acodec", "pcm_s16le",
            audio_path
        ]

        loop = asyncio.get_running_loop()

        try:
            await loop.run_in_executor(
                None,
                partial(
                    subprocess.run,
                    command,
                    check=True,
                    stdout=subprocess.PIPE,
                    stderr=subprocess.PIPE
                )
            )
            logger.info(f"âœ… éŸ³é¢‘æå–å®Œæˆ: {audio_path}")
            return audio_path

        except FileNotFoundError:
            err_msg = f"æœªæ‰¾åˆ° FFmpeg å¯æ‰§è¡Œæ–‡ä»¶ï¼Œè¯·æ£€æŸ¥ {ffmpeg_exe} æ˜¯å¦å­˜åœ¨"
            logger.error(f"âŒ ç³»ç»Ÿé”™è¯¯: {err_msg}")
            raise Exception(err_msg)
        except subprocess.CalledProcessError as e:
            err_msg = e.stderr.decode('utf-8', errors='ignore') if e.stderr else str(e)
            logger.error(f"âŒ FFmpeg å¤±è´¥: {err_msg}")
            raise Exception(f"FFmpeg è½¬ç å¤±è´¥: {err_msg}")
        except Exception as e:
            logger.error(f"âŒ FFmpeg æœªçŸ¥é”™è¯¯: {str(e)}")
            raise e


class AIEngine:
    """AI æœåŠ¡å¼•æ“ (API è°ƒç”¨) - å·²å¢åŠ è‡ªåŠ¨é‡è¯•æœºåˆ¶"""

    @staticmethod
    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=2, max=10),
        before_sleep=before_sleep_log(logger, logging.WARNING),
        reraise=True
    )
    async def transcribe_audio(audio_path: str) -> str:
        api_key = get_current_api_key("siliconflow_key", settings.SILICONFLOW_API_KEY)

        url = "https://api.siliconflow.cn/v1/audio/transcriptions"
        headers = {"Authorization": f"Bearer {api_key}"}

        if not os.path.exists(audio_path):
            raise FileNotFoundError(f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")

        # [æ ¸å¿ƒä¿®å¤] æ·»åŠ  trust_env=False ä»¥å¿½ç•¥ç³»ç»Ÿä»£ç†ï¼Œé˜²æ­¢ VPN å¹²æ‰°è¿æ¥
        async with httpx.AsyncClient(timeout=300.0, verify=False, trust_env=False) as client:
            with open(audio_path, "rb") as f:
                files = {'file': (os.path.basename(audio_path), f, "audio/wav")}
                data = {'model': "FunAudioLLM/SenseVoiceSmall"}

                logger.info(f"â˜ï¸ å¼€å§‹è°ƒç”¨ ASR API (Key: {api_key[:8]}...): {os.path.basename(audio_path)}")
                response = await client.post(url, headers=headers, files=files, data=data)

                if response.status_code != 200:
                    raise Exception(f"ASR API é”™è¯¯ ({response.status_code}): {response.text}")

                return response.json().get("text", "")

    @staticmethod
    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=2, max=10),
        before_sleep=before_sleep_log(logger, logging.WARNING),
        reraise=True
    )
    async def polish_text(raw_text: str) -> str:
        if not raw_text:
            return ""

        api_key = get_current_api_key("crec_key", settings.CREC_API_KEY)

        url = "https://ai-api.crec.cn/v1/chat/completions"
        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }

        system_prompt = (
            "ä½ æ˜¯ä¸€åä¸“ä¸šçš„æ–‡æœ¬ç¼–è¾‘ã€‚è¯·å¯¹ä»¥ä¸‹è¯­éŸ³è¯†åˆ«ç”Ÿæˆçš„åŸå§‹æ–‡æœ¬è¿›è¡Œæ¶¦è‰²ã€‚"
            "è¦æ±‚ï¼š1. ä¿®æ­£é”™åˆ«å­—å’Œå£è¯­åŒ–è¡¨è¾¾ï¼›2. æ·»åŠ æ­£ç¡®çš„æ ‡ç‚¹ç¬¦å·ï¼›3. åˆç†åˆ†æ®µï¼›"
            "4. ä¿æŒåŸæ„ä¸å˜ï¼Œä¸è¦éšæ„åˆ å‡é‡è¦ä¿¡æ¯;5. ä»…æä¾›æ¶¦è‰²åçš„å†…å®¹ï¼Œä¸å¢åŠ å…¶ä»–æè¿°"
        )

        payload = {
            "model": "deepseek-chat",
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": raw_text}
            ],
            "temperature": 0.1
        }
        model1 = payload.get("model")

        logger.info(f"ğŸ§  å¼€å§‹è°ƒç”¨ {model1}æ¶¦è‰² (Key: {api_key[:8]}...)...")
        async with httpx.AsyncClient(timeout=120.0, verify=False, trust_env=False) as client:
            response = await client.post(url, headers=headers, json=payload)
            if response.status_code != 200:
                raise Exception(f"LLM API é”™è¯¯ ({response.status_code}): {response.text}")
            return response.json()['choices'][0]['message']['content']

    @staticmethod
    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=2, max=10),
        before_sleep=before_sleep_log(logger, logging.WARNING),
        reraise=True
    )
    async def polish_document(doc_markdown: str) -> str:
        if not doc_markdown:
            return ""

        api_key = get_current_api_key("crec_key", settings.CREC_API_KEY)
        url = "https://ai-api.crec.cn/v1/chat/completions"
        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }

        system_prompt = (
            "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å­¦ä¹ èµ„æ–™æ•´ç†åŠ©æ‰‹ã€‚è¯·åœ¨ä¿æŒåŸæœ‰ç« èŠ‚ç»“æ„çš„å‰æä¸‹ï¼Œ"
            "å¯¹ä»¥ä¸‹é€šè¿‡ MinerU è§£æå¾—åˆ°çš„æ–‡æ¡£å†…å®¹è¿›è¡Œæ¶¦è‰²ï¼š"
            "1) ä¿®æ­£ OCR å¯èƒ½å¸¦æ¥çš„é”™å­—ï¼›2) å®Œå–„å¥å­å¹¶è¡¥å……å¿…è¦çš„è¯´æ˜ï¼›"
            "3) ä½¿ç”¨ Markdown å±‚çº§å±•ç¤ºç»“æœï¼›4) ä¿ç•™å›¾è¡¨åŠå…¬å¼çš„æ–‡å­—æè¿°ã€‚"
        )

        payload = {
            "model": "deepseek-chat",
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": doc_markdown}
            ],
            "temperature": 0.15
        }

        logger.info(f"ğŸ“š è°ƒç”¨æ–‡æ¡£æ¶¦è‰²æ¨¡å‹ (Key: {api_key[:8]}...)")
        async with httpx.AsyncClient(timeout=180.0, verify=False, trust_env=False) as client:
            response = await client.post(url, headers=headers, json=payload)
            if response.status_code != 200:
                raise Exception(f"LLM API é”™è¯¯ ({response.status_code}): {response.text}")
            return response.json()['choices'][0]['message']['content']

    @staticmethod
    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=2, max=10),
        before_sleep=before_sleep_log(logger, logging.WARNING),
        reraise=True
    )
    async def generate_fusion_notes(doc_markdown: str, transcript: str) -> str:
        if not (doc_markdown or transcript):
            return ""

        api_key = get_current_api_key("crec_key", settings.CREC_API_KEY)
        url = "https://ai-api.crec.cn/v1/chat/completions"
        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }

        system_prompt = (
            "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„è¯¾ç¨‹åŠ©æ•™ã€‚ç°åœ¨éœ€è¦æ ¹æ®è®²ä¹‰å†…å®¹ï¼ˆæ¥æºï¼šMinerU Markdownï¼‰"
            "ä¸è¯¾å ‚å½•éŸ³è½¬å†™æ–‡æœ¬ï¼ˆæ¥æºï¼šASRï¼‰ç”Ÿæˆä¸€ä»½èåˆç¬”è®°ï¼š"
            "- ä»¥è®²ä¹‰çš„ç« èŠ‚ä¸å±‚çº§ä¸ºéª¨æ¶ï¼›"
            "- å°†å½•éŸ³ä¸­çš„è§£é‡Šã€ä¸¾ä¾‹å’Œæ‹“å±•è¡¥å……åˆ°å¯¹åº”çš„å°èŠ‚ï¼›"
            "- å¯¹å…³é”®å…¬å¼/å›¾è¡¨ç»™å‡ºç®€è¦è§£é‡Šï¼›"
            "- è¾“å‡ºç»“æ„åŒ– Markdownï¼Œå±‚æ¬¡æ¸…æ™°ï¼Œå¯ç›´æ¥ç”¨äºå­¦ä¹ å¤ä¹ ã€‚"
        )

        user_content = (
            "èµ„æ–™ 1ï¼šè®²ä¹‰å†…å®¹\n" + doc_markdown +
            "\n\nèµ„æ–™ 2ï¼šè¯¾å ‚å½•éŸ³è½¬å†™\n" + transcript
        )

        payload = {
            "model": "deepseek-chat",
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_content}
            ],
            "temperature": 0.2
        }

        logger.info(f"ğŸ§© è°ƒç”¨èåˆç¬”è®°ç”Ÿæˆæ¨¡å‹ (Key: {api_key[:8]}...)")
        async with httpx.AsyncClient(timeout=240.0, verify=False, trust_env=False) as client:
            response = await client.post(url, headers=headers, json=payload)
            if response.status_code != 200:
                raise Exception(f"LLM API é”™è¯¯ ({response.status_code}): {response.text}")
            return response.json()["choices"][0]["message"]["content"]

    @staticmethod
    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=2, max=10),
        before_sleep=before_sleep_log(logger, logging.WARNING),
        reraise=True
    )
    async def generate_note(text: str, template_prompt: str) -> str:
        if not text:
            return ""

        api_key = get_current_api_key("crec_key", settings.CREC_API_KEY)

        url = "https://ai-api.crec.cn/v1/chat/completions"
        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }

        payload = {
            "model": "deepseek-chat",
            "messages": [
                {"role": "system", "content": template_prompt},
                {"role": "user", "content": f"è¯·æ ¹æ®ä¸Šè¿°è¦æ±‚ï¼Œæ€»ç»“ä»¥ä¸‹æ–‡æœ¬ï¼š\n\n{text}"}
            ],
            "temperature": 0.3
        }
        model2 = payload.get("model")

        logger.info(f"ğŸ“ è°ƒç”¨{model2}å¼€å§‹ç”Ÿæˆæœ€ç»ˆç¬”è®°...")
        async with httpx.AsyncClient(timeout=120.0, verify=False, trust_env=False) as client:
            response = await client.post(url, headers=headers, json=payload)
            if response.status_code != 200:
                raise Exception(f"LLM API é”™è¯¯ ({response.status_code}): {response.text}")
            return response.json()['choices'][0]['message']['content']
